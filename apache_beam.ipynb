{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start dataflow job\n",
    "# python dataflow_python_examples/data_transformation.py \\\n",
    "#   --project=$PROJECT \\\n",
    "#   --region=us-east5 \\\n",
    "#   --runner=DataflowRunner \\\n",
    "#   --staging_location=gs://$PROJECT/test \\\n",
    "#   --temp_location gs://$PROJECT/test \\\n",
    "#   --input gs://$PROJECT/data_files/head_usa_names.csv \\\n",
    "#   --save_main_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"apache-beam[interactive]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners.interactive import interactive_beam as ib\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.io.jdbc import ReadFromJdbc\n",
    "from apache_beam.io.jdbc import WriteToJdbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing pipeline options\n",
    "class Myoptions(PipelineOptions):\n",
    "    @classmethod\n",
    "    def _add_argparse_args(cls, parser):\n",
    "        parser.add_argument(\n",
    "            '--input', \n",
    "            help='Input for the pipeline', \n",
    "            default='gs://dataflow-samples/shakespeare/kinglear.txt')\n",
    "        \n",
    "        parser.add_argument(\n",
    "            '--output',\n",
    "            help='Output for the pipeline',\n",
    "            default='gs://$PROJECT/output/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beam.Row and infering schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(bank='Wells Fargo', purchase_amount=103.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe212ecaeb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "class Transaction(typing.NamedTuple):\n",
    "    bank: str\n",
    "    purchase_amount: float\n",
    "\n",
    "p = beam.Pipeline()\n",
    "output = (\n",
    "          p\n",
    "          | beam.Create([{\"bank\": \"Wells Fargo\", \"purchase_amount\": 103.30}])\n",
    "          | beam.Map(lambda item : beam.Row(bank=item[\"bank\"], purchase_amount = item[\"purchase_amount\"])).with_output_types(Transaction)\n",
    "          | beam.Map(print)\n",
    "        )\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beam.Select and infering schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(bank='Wells Fargo', purchase_amount=103.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe212b5e7f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = beam.Pipeline()\n",
    "\n",
    "output = (\n",
    "          p\n",
    "          | beam.Create([{\"bank\": \"Wells Fargo\", \"purchase_amount\": 103.30}])\n",
    "          | beam.Select(bank = lambda item: item[\"bank\"], purchase_amount = lambda item: item[\"purchase_amount\"]).with_output_types(Transaction)\n",
    "          | beam.Map(print)\n",
    "        )\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a DoFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('who', 3)\n",
      "('is', 2)\n",
      "('the', 3)\n",
      "('man', 3)\n",
      "('from', 4)\n",
      "('the', 3)\n",
      "('moon', 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe1f5ac78b0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComputeWordLength(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        return [(element , len(element))]\n",
    "    \n",
    "p = beam.Pipeline()\n",
    "# creating Pcollection from data in memory\n",
    "words = beam.Create('who is the man from the moon'.split())\n",
    "wordlengths = p | words | beam.ParDo(ComputeWordLength()) | beam.Map(print)\n",
    "p.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing side inputs to ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Lorem ipsum dolor sit amet consectetur adipisicing elit. Quisquam vitae unde voluptatibus dolores perspiciatis, quis amet eveniet aperiam atque placeat laborum? Consequuntur illo accusamus, praesentium doloremque eaque recusandae earum perspiciatis!.\"\"\"\n",
    "\n",
    "p = beam.Pipeline()\n",
    "\n",
    "words = p | beam.Create(text.split())\n",
    "\n",
    "def filter_using_length(word, lower_bound, upper_bound=float('inf')):\n",
    "    if lower_bound <= len(word) <= upper_bound:\n",
    "        yield word\n",
    "\n",
    "average_word_len = (\n",
    "    words\n",
    "    | beam.Map(len)\n",
    "    | beam.CombineGlobally(beam.combiners.MeanCombineFn()))\n",
    "\n",
    "small_words = words | \"small words\" >> beam.FlatMap(filter_using_length, lower_bound=1, upper_bound=3)\n",
    "larger_words = words | \"large words\" >> beam.FlatMap(filter_using_length, lower_bound= beam.pvalue.AsSingleton(average_word_len))\n",
    "p.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tagging multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fa297107310>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = beam.Pipeline()\n",
    "numbers = p | beam.Create([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "def even_odd_filter(x):\n",
    "    yield beam.pvalue.TaggedOutput('odd' if x % 2 else 'even', x)\n",
    "    if x % 10 == 0:\n",
    "        yield x\n",
    "\n",
    "results = numbers | beam.FlatMap(even_odd_filter).with_outputs()#('odd', 'even')\n",
    "p.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating composite transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeWordLength(beam.PTransform):\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | beam.Map(lambda x: len(x))\n",
    "    \n",
    "    p = beam.Pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CombineFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fa2c2c13220>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComputeAverag(beam.CombineFn):\n",
    "    def create_accumulator(self):\n",
    "        return (0.0, 0)\n",
    "    \n",
    "    def add_input(self, sum_count, input):\n",
    "        (sum, count) = sum_count\n",
    "        return sum + input, count + 1\n",
    "    \n",
    "    def merge_accumulators(self, accumulators):\n",
    "        sums, counts = zip(*accumulators)\n",
    "        return sum(sums), sum(counts)\n",
    "    \n",
    "    def extract_output(self, sum_count):\n",
    "        (sum, count) = sum_count\n",
    "        return sum/count if count else float('NaN')\n",
    "\n",
    "p = beam.Pipeline()\n",
    "# creating Pcollection from data in memory\n",
    "pcoll = beam.Create([1, 2, 3, 4, 5])\n",
    "average = p | pcoll | beam.CombineGlobally(ComputeAverag()) | beam.Map(print)\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('amy', {'emails': ['amy@example.com'], 'phones': ['111-222-3333', '333-444-5555']})\n",
      "('james', {'emails': [], 'phones': ['222-333-4444']})\n",
      "('carl', {'emails': ['carl@example.com', 'carl@email.com'], 'phones': ['444-555-6666']})\n",
      "('julia', {'emails': ['julia@example.com'], 'phones': []})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe1f373db20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = beam.Pipeline()\n",
    "\n",
    "emails_list = [\n",
    "    ('amy', 'amy@example.com'),\n",
    "    ('carl', 'carl@example.com'),\n",
    "    ('julia', 'julia@example.com'),\n",
    "    ('carl', 'carl@email.com'),\n",
    "]\n",
    "phones_list = [\n",
    "    ('amy', '111-222-3333'),\n",
    "    ('james', '222-333-4444'),\n",
    "    ('amy', '333-444-5555'),\n",
    "    ('carl', '444-555-6666'),\n",
    "]\n",
    "\n",
    "emails = p | 'CreateEmails' >> beam.Create(emails_list)\n",
    "phones = p | 'CreatePhones' >> beam.Create(phones_list)\n",
    "\n",
    "results = ({'emails': emails, 'phones': phones} | beam.CoGroupByKey()) | beam.Map(print)\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 'data/IBM.csv'\n",
    "pipeline = beam.Pipeline()\n",
    "\n",
    "outputs = (\n",
    "    pipeline\n",
    "    | 'ReadData' >> beam.io.ReadFromText(input_data, skip_header_lines=1)\n",
    "    | 'SplitData' >> beam.Map(lambda x: x.split(','))\n",
    "    | 'FilterData' >> beam.Filter(lambda x: x[1] == 'Yes')\n",
    "    | 'flatmap' >> beam.FlatMap(lambda x: x)\n",
    "    | 'pair words with 1' >> beam.Map(lambda x: (x, 1))\n",
    "    # | \"group by key\" >> beam.GroupByKey()\n",
    "    # | 'count words' >> beam.Map(lambda x: (x[0], sum(x[1])))\n",
    "    | 'group and sum' >> beam.CombinePerKey(sum)\n",
    "    | 'print' >> beam.Map(print)\n",
    ")\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.show_graph(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = p | beam.Create([1, 10, 100, 1000])\n",
    "\n",
    "def bounded_sum(values, bound=500):\n",
    "  return min(sum(values), bound)\n",
    "\n",
    "small_sum = pc | \"small sum\" >> beam.CombineGlobally(bounded_sum)  # [500]\n",
    "large_sum = pc | \"large sum\" >> beam.Map(lambda x : x**2) | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc53176c040>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "\"dbname\":\"bigdata\",\n",
    "\"user\":\"postgres\",\n",
    "\"password\":\"*****\",\n",
    "\"host\":\"localhost\",\n",
    "\"port\":\"5432\"}\n",
    "\n",
    "conn = psycopg2.connect(**config)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select * from employee\")\n",
    "headers = [desc.name for desc in cur.description]\n",
    "\n",
    "p = beam.Pipeline()\n",
    "res = (\n",
    "    p\n",
    "    | \"input\" >> beam.Create(cur.fetchall())\n",
    "    | beam.Map(lambda row : beam.Row(name= row[1], dept=row[2], salary = row[3]))\n",
    "    | beam.GroupBy(\"dept\")\\\n",
    "        .aggregate_field(\"name\", beam.combiners.CountCombineFn(), \"total_employees\")\\\n",
    "            .aggregate_field(\"salary\", sum, \"total_salary\")\\\n",
    "                .aggregate_field(\"salary\", beam.combiners.MeanCombineFn(), \"avg_salaries\")\n",
    "    | \"format\" >> beam.Map(lambda row : f\"{row.dept},{row.total_employees},{row.total_salary},{row.avg_salaries}\")\n",
    "    | \"save to file\" >> beam.io.WriteToText(\"data/output.txt\")\n",
    "    )\n",
    "p.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark-de-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
